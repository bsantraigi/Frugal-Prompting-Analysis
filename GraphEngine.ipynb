{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90affb-1055-4a61-9e90-8b4eb7c40ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f72c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('plots/TC', exist_ok=True)\n",
    "os.makedirs('plots/MSC', exist_ok=True)\n",
    "os.makedirs('processed/TC', exist_ok=True)\n",
    "os.makedirs('processed/MSC', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94227915-2fdf-497e-aee3-58d50ce6acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sheet = 'Multi Session Chat View 1'\n",
    "# sheet = 'Topical Chat View 1'\n",
    "# df = pd.read_excel('ITL_20230521.xlsx', sheet_name=sheet)\n",
    "# df = df.loc[df.Model != \"Gap\"]\n",
    "\n",
    "# Remove unnamed columns\n",
    "# df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# New Results from data/evals.csv\n",
    "df = pd.read_csv('data/evals.csv')\n",
    "# dataset_prefix = \"MSC\"\n",
    "dataset_prefix = \"TC\"\n",
    "df = df.loc[df.dataset == dataset_prefix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_prefix == \"MSC\":\n",
    "    # title_fontsize = 36\n",
    "    legend_fontsize = 18\n",
    "    label_fontsize = 24\n",
    "else:\n",
    "    # dataset_prefix = \"TC\"\n",
    "    # title_fontsize = \n",
    "    legend_fontsize = 20\n",
    "    label_fontsize = 20\n",
    "\n",
    "    # Rename \"Knowledge\" as \"Persona Signal\"\n",
    "    df = df.rename(columns={\"Knowledge\": \"Persona Signal\"})\n",
    "\n",
    "# Set to a common linux font\n",
    "fonts = {'family' : 'serif',\n",
    "        'serif' : 'Caladea',\n",
    "        # 'weight' : 'bold',\n",
    "        'size'   : 36\n",
    "        }\n",
    "# For some wierd reason you need to set the \n",
    "# font size like following\n",
    "# 36 for MSC\n",
    "# 40 for TC \n",
    "\n",
    "matplotlib.rc('font', **fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709e3d7-3c8e-4fed-99ea-28d2886cefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prompt Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de212a5-6939-4c1f-9fb3-8e7614976a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prompt Type'].replace(\"Orig(.*)\", \"FS-ICL\\\\1\", regex=True, inplace=True)\n",
    "df['Prompt Type'].replace(\"Short(.*)\", \"ZS-ICL\\\\1\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop for values ppl1, ppl2, Exp1, Exp2. Or if it is null\n",
    "df = df.loc[~df['Prompt Type'].isin(['ppl1', 'ppl2', 'Exp1', 'Exp2'])]\n",
    "df = df.loc[~df['Prompt Type'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ebaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prompt Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b967dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"History Signal\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12545625-d414-4c50-bf68-115f0fb95759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSC Rules\n",
    "df['History Signal'].replace(r\"Prev (\\d+)\", r\"Recent-\\1\", regex=True, inplace=True)\n",
    "df['History Signal'].replace(\"4 Semant.*\", \"Semantic-4\", regex=True, inplace=True)\n",
    "df['History Signal'].replace(r\"(\\d+) semantic sim \\(simcse\\)\", r\"Semantic-\\1\", regex=True, inplace=True)\n",
    "df['History Signal'].replace(\"semantic sim (simcse)\", \"Semantic-4\", inplace=True)\n",
    "df['History Signal'].replace(\"Pegasus cnn/dm\", \"Pegasus-CD\", inplace=True)\n",
    "df['Persona Signal'].replace(\"Pegasus cnn/dm\", \"Pegasus-CD\", inplace=True)\n",
    "# # TC Conversion Rules\n",
    "df['History Signal'].replace(\"4 semantic sim (simcse)\", \"Semantic-4\", inplace=True)\n",
    "df['History Signal'].replace(\"4 semantic sim\", \"Semantic-4\", regex=True, inplace=True)\n",
    "df['Model'].replace(\"T-k instruct\", \"Tk-Instruct\", inplace=True)\n",
    "df['Model'].replace(\"Tk-instruct\", \"Tk-Instruct\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ee1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"History Signal\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18044f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Model'].replace(\"text-davinci-003\", \"GPT-3\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with Persona Signal = PegasusFT\n",
    "df = df.loc[df['Persona Signal'] != \"PegasusFT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e18ef9-ab0c-44a5-8cd4-f4936bd0acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = ['Model', 'Method', 'Persona Signal', 'History Signal', 'Prompt Type',\n",
    "       'BLEU', 'METEOR', 'rouge1', 'rouge2', 'rougeL', 'Bert-p', 'Bert-r',\n",
    "       'Bert-f1', 'DEB', 'Bleurt', 'output', 'prompt']\n",
    "df = df[used_cols]\n",
    "df['total_budget'] = df['output'] + df['prompt']\n",
    "df['BLEURT']=df['Bleurt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a7ba5-a852-41eb-a4a2-4584c5d4775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['Model', 'Prompt Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set and increase Matplotlib font\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "# plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "# plt.rcParams['font.size'] = 24\n",
    "\n",
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 32}\n",
    "\n",
    "# matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_row_cols(df):\n",
    "    # print(\"Shape of df: {}\".format(df.shape))\n",
    "    # Print the columns/rows that will be dropped\n",
    "    # print(\"Columns with all nan: {}\".format(df.columns[df.isnull().all(axis=0)]))\n",
    "    # print(\"Rows with all nan: {}\".format(df.index[df.isnull().all(axis=1)]))\n",
    "    # Drop rows with all nan\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    # Drop columns with all nan\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    # print(\"Shape of df after dropping rows and columns with all nan: {}\".format(df.shape))\n",
    "    return df\n",
    "\n",
    "def scatter_plot_pivoted_df(pivoted_df, metric, save_path, is_roi=False):\n",
    "    # Print shape\n",
    "    # print(pivoted_df)\n",
    "\n",
    "    print(\"Metric: {}\".format(metric))\n",
    "    print(\"Save path: {}\".format(save_path))\n",
    "    \n",
    "    # Check if any row or column is all nan\n",
    "    # if pivoted_df.isnull().all(axis=1).any() or pivoted_df.isnull().all(axis=0).any():\n",
    "    #     print(\"Skipping plot because of all nan row or column for {} @ {}\".format(metric, save_path))\n",
    "    #     return\n",
    "\n",
    "    # # Drop rows with all nan\n",
    "    # pivoted_df = pivoted_df.dropna(axis=0, how='all')\n",
    "    # # Drop columns with all nan\n",
    "    # pivoted_df = pivoted_df.dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "    if pivoted_df.shape[0] == 0:\n",
    "        print(\"Skipping plot for {} @ {}\".format(metric, save_path))\n",
    "        return\n",
    "\n",
    "    colors = sns.color_palette('Paired', len(pivoted_df.columns))\n",
    "    markers = ['o', 'v', 's', 'p', 'P', '*', 'X', 'D', 'd', '1', '2', '3', '4', '8', 'h', 'H', 'x', 'X', 'D', 'd', '|', '_']\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    # print(pivoted_df.index.tolist())\n",
    "    # Scatter plot\n",
    "    models = pivoted_df.columns\n",
    "    for i, model in enumerate(models):\n",
    "        x = pivoted_df.index.tolist()\n",
    "        y = pivoted_df[model]\n",
    "        # y shouldn't be all nans\n",
    "        if y.isnull().all():\n",
    "            continue\n",
    "        lbl = f\"{model[0]} ({model[1].replace('-ICL', '')})\"\n",
    "        ax.scatter(x, y, color = colors[i], marker = markers[i], label=lbl, s=150)\n",
    "\n",
    "    # Set x-axis labels\n",
    "    ax.set_xticks(list(range(len(pivoted_df.index.tolist()))))\n",
    "    ax.set_xticklabels(pivoted_df.index.tolist(), rotation=90, fontsize=label_fontsize)\n",
    "\n",
    "    # Set y-axis tick font\n",
    "    ax.tick_params(axis='y', labelsize=label_fontsize)\n",
    "\n",
    "    # Add legend at the top of the figure\n",
    "    # show in a single row\n",
    "    # Smaller font size\n",
    "    if len(models) <= 5:\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.26), ncol=2, fontsize=legend_fontsize)\n",
    "    else:\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.43), ncol=2, fontsize=legend_fontsize)\n",
    "\n",
    "    ax.grid(True, axis='y')\n",
    "    # x-axis label\n",
    "    ax.set_xlabel('History Signal', fontsize=label_fontsize)\n",
    "    # y-axis label\n",
    "    if is_roi:\n",
    "        ax.set_ylabel(f'ROI ({metric})', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(f'{metric}', fontsize=label_fontsize)\n",
    "\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # Save such that legends are fitted within the figure\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "    # Separate plot averaged over all models (two groups FS and ZS)\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    # Scatter plot\n",
    "    models = pivoted_df.columns\n",
    "    fs_models = [model for model in models if \"FS\" in model[1]]\n",
    "    x = pivoted_df.index.tolist()\n",
    "    y = pivoted_df[fs_models].mean(axis=1)\n",
    "    ax.scatter(x, y, color = colors[0], marker = markers[0], label='Model Avg. (FS)', s=150)\n",
    "\n",
    "\n",
    "    zs_models = [model for model in models if \"ZS\" in model[1]]\n",
    "    y = pivoted_df[zs_models].mean(axis=1)\n",
    "    ax.scatter(x, y, color = colors[1], marker = markers[1], label='Model Avg. (ZS)', s=150)\n",
    "\n",
    "    # Set x-axis labels\n",
    "    ax.set_xticks(list(range(len(pivoted_df.index.tolist()))))\n",
    "    ax.set_xticklabels(pivoted_df.index.tolist(), rotation=90, fontsize=label_fontsize)\n",
    "\n",
    "    # Set y-axis tick font\n",
    "    ax.tick_params(axis='y', labelsize=label_fontsize)\n",
    "    \n",
    "    # Add legend at the top of the figure\n",
    "    # show in a single row\n",
    "    # Smaller font size\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.16), ncol=2, fontsize=legend_fontsize)\n",
    "\n",
    "    ax.grid(True, axis='y')\n",
    "    # x-axis label\n",
    "    ax.set_xlabel('History Signal', fontsize=label_fontsize)\n",
    "    # y-axis label\n",
    "    if is_roi:\n",
    "        ax.set_ylabel(f'ROI ({metric})', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(f'{metric}', fontsize=label_fontsize)\n",
    "\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # Save such that legends are fitted within the figure\n",
    "    plt.savefig(save_path.replace('.pdf', '_avg.pdf'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbf034-e258-436d-8971-a45448572559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ROI(df_perf, df_budget):\n",
    "    # print(df_perf)\n",
    "    assert df_perf.shape == df_budget.shape\n",
    "    # Find the rows with index \"None_0\" or \"No DH, no BI\", only one of these should exist\n",
    "    if \"None_0\" in df_perf.index:\n",
    "        X_perf = df_perf.loc['None_0']\n",
    "        X_budget = df_budget.loc['None_0']\n",
    "    # elif \"No DH, no BI\" in df_perf.index:\n",
    "    #     assert \"None_0\" not in df_perf.index\n",
    "    #     X_perf = df_perf.loc['No DH, no BI']\n",
    "    #     X_budget = df_budget.loc['No DH, no BI']\n",
    "    else:\n",
    "        raise ValueError(\"None_0 not found in df_perf.index.\")\n",
    "\n",
    "    # assert df_perf.index[0] == \"None\" or df_perf.index[0] == \"No DH, no BI\"\n",
    "    # Match index and column order\n",
    "    assert df_perf.index.tolist() == df_budget.index.tolist()\n",
    "    assert df_perf.columns.tolist() == df_budget.columns.tolist()\n",
    "\n",
    "    # Calculate ROI: w.r.t to best baseline in \"None\"\n",
    "    # df_delta = df_perf - X_perf\n",
    "    # df_delta_budget = df_budget - X_budget\n",
    "    # Unnormalized ROI\n",
    "    df_delta = df_perf\n",
    "    df_delta_budget = df_budget\n",
    "    df_roi = 10_000*df_delta / df_delta_budget\n",
    "    return df_roi.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4eb935-cd66-48f0-a026-d3f1b7557ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_sub_df_persona(sub_df, baseline_df, signal, prompt_type_groups, metric, all_subframes, dataset_prefix):\n",
    "    for prompt_types_name, prompt_types in prompt_type_groups.items():\n",
    "        # prompt_sub_df = sub_df\n",
    "        prompt_sub_df = sub_df[sub_df['Prompt Type'].isin(prompt_types)]\n",
    "        # Remove old baselines\n",
    "        # prompt_sub_df = sub_df[~(sub_df['History Signal'] == \"None\")]\n",
    "        # Rename this baseline to \"None_1\"\n",
    "        prompt_sub_df.loc[prompt_sub_df['History Signal'] == 'None', 'History Signal'] = 'None_1'\n",
    "        \n",
    "        # Add common baseline - prompt type would be non-ppl\n",
    "        # prompt_baseline_df = baseline_df[baseline_df['Prompt Type'].isin(prompt_types)]\n",
    "        prompt_baseline_df = baseline_df[baseline_df['Prompt Type'].isin(prompt_type_groups['normal'])]\n",
    "        # overwrite prompt type of baseline\n",
    "        for i, row in prompt_baseline_df.iterrows():\n",
    "            if row['Prompt Type'] == 'FS-ICL':\n",
    "                prompt_baseline_df.at[i, 'Prompt Type'] = prompt_types[0]\n",
    "            elif row['Prompt Type'] == 'ZS-ICL':\n",
    "                prompt_baseline_df.at[i, 'Prompt Type'] = prompt_types[1]\n",
    "        # rename this baseline to \"None_0\"\n",
    "        prompt_baseline_df['History Signal'] = \"None_0\"\n",
    "        prompt_sub_df  = prompt_sub_df.append(prompt_baseline_df)\n",
    "        \n",
    "        print(\"History:\", prompt_sub_df['History Signal'].unique())\n",
    "        print(\"Prompt types:\", prompt_sub_df['Prompt Type'].unique())\n",
    "\n",
    "        # Remove blenderbot\n",
    "        prompt_sub_df = prompt_sub_df[~prompt_sub_df['Model'].isin([\"BlenderBot-3B\"])]\n",
    "        if len(prompt_sub_df) <= 0:\n",
    "            continue\n",
    "\n",
    "        pivoted_df = prompt_sub_df.pivot(index='History Signal', columns=['Model', 'Prompt Type'], values=metric)        \n",
    "        pivoted_budget = prompt_sub_df.pivot(index='History Signal', columns=['Model', 'Prompt Type'], values='total_budget')\n",
    "        pivoted_input_budget = prompt_sub_df.pivot(index='History Signal', columns=['Model', 'Prompt Type'], values='prompt')\n",
    "\n",
    "        # Fixed model order\n",
    "        history_order = [\"None_0\", \"None_1\", \"BART\",\"Full\", \"Pegasus-CD\", \"PegasusFT\", \n",
    "                         \"Recent-1\", \"Recent-2\", \"Recent-4\", \"Recent-8\", \"Recent-10\", \"Recent-16\", \n",
    "                         \"Semantic-1\", \"Semantic-2\", \"Semantic-4\", \"Semantic-8\", \"Semantic-10\", \"Semantic-16\",\n",
    "                         ]\n",
    "        # remove history signals that are not in the data\n",
    "        history_order = [h for h in history_order if h in prompt_sub_df['History Signal'].unique()]\n",
    "        pivoted_df = pivoted_df.reindex(history_order)\n",
    "        pivoted_budget = pivoted_budget.reindex(history_order)\n",
    "        pivoted_input_budget = pivoted_input_budget.reindex(history_order)\n",
    "\n",
    "        # ROI: based on first row (None)\n",
    "        ROI = calculate_ROI(pivoted_df, pivoted_budget)\n",
    "\n",
    "        models = ['flanT5-XL',\n",
    "                'T0',\n",
    "                'Tk-Instruct',\n",
    "                'GPT-3']\n",
    "        # remove models that are not in the data\n",
    "        models = [m for m in models if m in prompt_sub_df['Model'].unique()] \n",
    "        # icls = [\"ZS-ICL\", \"FS-ICL\", \"ZS-ICL (ppl)\", \"FS-ICL (ppl)\"]\n",
    "        icls = prompt_types\n",
    "        model_icl_pairs = list(itertools.product(models, icls))\n",
    "        pivoted_df = pivoted_df.reindex(model_icl_pairs, axis=1)\n",
    "        pivoted_budget = pivoted_budget.reindex(model_icl_pairs, axis=1)\n",
    "        pivoted_input_budget = pivoted_input_budget.reindex(model_icl_pairs, axis=1)\n",
    "        ROI = ROI.reindex(model_icl_pairs, axis=1)\n",
    "\n",
    "        # Clean the dataframes of empty columns/rows\n",
    "        pivoted_df = drop_nan_row_cols(pivoted_df)\n",
    "        pivoted_budget = drop_nan_row_cols(pivoted_budget)\n",
    "        pivoted_input_budget = drop_nan_row_cols(pivoted_input_budget)\n",
    "        ROI = drop_nan_row_cols(ROI)\n",
    "\n",
    "        all_subframes[signal + \"_\" + prompt_types_name] = pivoted_df\n",
    "        all_subframes[signal + \"_\" + prompt_types_name + \"_budget\"] = pivoted_budget\n",
    "        all_subframes[signal + \"_\" + prompt_types_name + \"_ibudget\"] = pivoted_input_budget\n",
    "        if \"None_0\" in pivoted_df.index:\n",
    "            all_subframes[signal + \"_\" + prompt_types_name + \"_ROI\"] = ROI\n",
    "        else:\n",
    "            print(\"Cannot calculate ROI without NoHistory baseline (i.e. None).\")\n",
    "\n",
    "        # Plot absolute metrics\n",
    "        f1 = f'plots/{dataset_prefix}/{metric}_{signal}_{prompt_types_name}.pdf'\n",
    "        scatter_plot_pivoted_df(pivoted_df, metric, f1)\n",
    "\n",
    "        # Plot ROI\n",
    "        if \"None\" in pivoted_df.index:\n",
    "            f2 = f'plots/{dataset_prefix}/{metric}_{signal}_{prompt_types_name}_ROI.pdf'\n",
    "            scatter_plot_pivoted_df(ROI, metric, f2, is_roi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_runs(framedict, metric, dataset_prefix, target=\"ppl\"):\n",
    "    assert target in [\"normal\", \"ppl\"], \"merge target must be either normal or ppl\"\n",
    "\n",
    "    # DF Merged, Only for None_ppl, PegasusFT_*\n",
    "    def is_budget(x):\n",
    "        return x.endswith(\"_budget\") or x.endswith(\"_ibudget\")\n",
    "    \n",
    "    def is_roi(x):\n",
    "        return x.endswith(\"_ROI\")\n",
    "    \n",
    "    def is_runlist(x):\n",
    "        # Set of runs that we want to keep\n",
    "        # No persona and PegasusFT-based persona summary\n",
    "        return x.startswith(\"None\") or x.startswith(\"PegasusFT\") or x.startswith(\"Pegasus-CD\")\n",
    "\n",
    "    modded_run_keys = list(\n",
    "        filter(\n",
    "            lambda x: is_runlist(x) and not is_roi(x) and not is_budget(x),\n",
    "            framedict.keys()\n",
    "        )\n",
    "    )\n",
    "    df_modded_runs_group = {k: v for k, v in framedict.items() if k in modded_run_keys}\n",
    "\n",
    "    budget_keys = list(\n",
    "        filter(lambda x: is_budget(x), framedict.keys())\n",
    "    )\n",
    "    df_budgets = {k.replace(\"_budget\", \"\"): v for k, v in framedict.items() if k in budget_keys}\n",
    "    df_budgets = {k: v for k, v in df_budgets.items() if k in df_modded_runs_group}\n",
    "\n",
    "    # Baseline is None_normal, index \"None\"\n",
    "    df_baseline = df_modded_runs_group[\"None_normal\"].iloc[:1]\n",
    "    df_baseline_budget = df_budgets[\"None_normal\"].iloc[:1]\n",
    "    # check that history is None\n",
    "    assert df_baseline.index[0] == \"None_0\" and df_baseline_budget.index[0] == \"None_0\", \"Baseline must be None_0\"\n",
    "\n",
    "    to_remove = []\n",
    "    if target == \"ppl\":\n",
    "        for k, v in df_modded_runs_group.items():\n",
    "            if k.endswith(\"_normal\"):\n",
    "                to_remove.append(k)\n",
    "    elif target == \"normal\":\n",
    "        for k, v in df_modded_runs_group.items():\n",
    "            if k.endswith(\"_ppl\"):\n",
    "                to_remove.append(k)\n",
    "        # del df_modded_runs_group[\"None_ppl\"]\n",
    "        # del df_budgets[\"None_ppl\"]\n",
    "    print(\"TO REMOVE:\", to_remove)\n",
    "    for k in to_remove:\n",
    "        del df_modded_runs_group[k]\n",
    "        del df_budgets[k]\n",
    "    print(\"REMAINING:\", df_modded_runs_group.keys())\n",
    "\n",
    "\n",
    "    # Remove (ppl) from column names and \"None\" history rows\n",
    "    df_modded_runs_group = {k: v.rename(columns=lambda x: x.replace(\" (ppl)\", \"\")) for k, v in df_modded_runs_group.items()}\n",
    "    # df_modded_runs_group = {k: v.drop(\"None\") for k, v in df_modded_runs_group.items()}\n",
    "\n",
    "    # Do the same for budgets\n",
    "    df_budgets = {k: v.rename(columns=lambda x: x.replace(\" (ppl)\", \"\")) for k, v in df_budgets.items()}\n",
    "    # df_budgets = {k: v.drop(\"None\") for k, v in df_budgets.items()}\n",
    "\n",
    "    # Create merged df\n",
    "    # Keys as a new column, and reset index, history as another new column\n",
    "    df_merged = pd.concat(df_modded_runs_group, keys=df_modded_runs_group.keys()).reset_index(level=1)\n",
    "    df_merged_budget = pd.concat(df_budgets, keys=df_budgets.keys()).reset_index(level=1)\n",
    "\n",
    "    # Reset index again, rename the old one to \"Config\"\n",
    "    df_merged = df_merged.reset_index().rename(columns={\"index\": \"Config\"})\n",
    "    df_merged_budget = df_merged_budget.reset_index().rename(columns={\"index\": \"Config\"})\n",
    "\n",
    "    # Add the baseline row at the top\n",
    "    # TODO: It don't think this is necessary anymore, so I commented it out (May 21, 2023)\n",
    "    # df_merged = df_merged.append(df_baseline.reset_index().rename(columns={\"index\": \"Config\"}))\n",
    "    # df_merged_budget = df_merged_budget.append(df_baseline_budget.reset_index().rename(columns={\"index\": \"Config\"}))\n",
    "\n",
    "    # Move last row to the top\n",
    "    df_merged = df_merged.iloc[-1:].append(df_merged.iloc[:-1]).reset_index(drop=True)\n",
    "    df_merged_budget = df_merged_budget.iloc[-1:].append(df_merged_budget.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "    # Final names for DH\n",
    "    replacements_2 = {\n",
    "        # \"None\": \"No DH, no BI\",\n",
    "        \"None_1\": \"No DH, no BI\",\n",
    "        \"BART\": \"BART-D\",\n",
    "        \"PegasusFT\": \"Pegasus-DS\",\n",
    "        \"Pegasus-CD\": \"Pegasus-CD\",\n",
    "    }\n",
    "    df_merged[\"History Signal\"] = df_merged[\"History Signal\"].replace(replacements_2)\n",
    "    df_merged_budget[\"History Signal\"] = df_merged_budget[\"History Signal\"].replace(replacements_2)\n",
    " \n",
    "    if target==\"ppl\":\n",
    "        replace_dict = {\n",
    "            \"None_ppl\": \"\",\n",
    "            \"PegasusFT_ppl\": \" + BI(P_FT)\",\n",
    "            \"Pegasus-CD_ppl\": \" + BI\"\n",
    "        }\n",
    "    elif target==\"normal\":\n",
    "        replace_dict = {\n",
    "            \"None_normal\": \"\",\n",
    "            \"PegasusFT_normal\": \" + BI(P_FT)\",\n",
    "            \"Pegasus-CD_normal\": \" + BI\"\n",
    "        }\n",
    "\n",
    "\n",
    "    df_merged[\"Config\"] = df_merged[\"Config\"].fillna(\"\").replace(replace_dict)\n",
    "    df_merged_budget[\"Config\"] = df_merged_budget[\"Config\"].fillna(\"\").replace(replace_dict)\n",
    "\n",
    "    # Add config to history signal\n",
    "    df_merged[\"History Signal\"] = df_merged[\"History Signal\"] + df_merged[\"Config\"]\n",
    "    df_merged_budget[\"History Signal\"] = df_merged_budget[\"History Signal\"] + df_merged_budget[\"Config\"]\n",
    "\n",
    "    # One \"None_0 + BI\" might have been added, remove it -- None_0 is results from the orig none_none setup\n",
    "    df_merged = df_merged[df_merged[\"History Signal\"] != \"None_0 + BI\"]\n",
    "    df_merged_budget = df_merged_budget[df_merged_budget[\"History Signal\"] != \"None_0 + BI\"]\n",
    "\n",
    "    # Drop all None_0 **\n",
    "    # df_merged = df_merged[df_merged[\"History Signal\"] != \"None_0\"]\n",
    "    # df_merged_budget = df_merged_budget[df_merged_budget[\"History Signal\"] != \"None_0\"]\n",
    "\n",
    "    # No DH, No BI + BI -> Only BI\n",
    "    df_merged[\"History Signal\"] = df_merged[\"History Signal\"].replace({\"No DH, no BI + BI\": \"Only BI\"})\n",
    "    df_merged_budget[\"History Signal\"] = df_merged_budget[\"History Signal\"].replace({\"No DH, no BI + BI\": \"Only BI\"})\n",
    "    \n",
    "   # df_merged[\"History Signal\"] = df_merged[\"History Signal\"].replace({\"None\": \"No DH, No BI\"})\n",
    "    # df_merged_budget[\"History Signal\"] = df_merged_budget[\"History Signal\"].replace({\"None\": \"No DH, No BI\"})\n",
    "\n",
    "    # make history signal the index column\n",
    "    df_merged = df_merged.set_index(\"History Signal\")\n",
    "    df_merged_budget = df_merged_budget.set_index(\"History Signal\")\n",
    "\n",
    "    # drop config\n",
    "    df_merged = df_merged.drop(\"Config\", axis=1)\n",
    "    df_merged_budget = df_merged_budget.drop(\"Config\", axis=1)\n",
    "\n",
    "    assert (df_merged.index == df_merged_budget.index).all()\n",
    "\n",
    "    # Convert the column names to tuples by splitting on space\n",
    "    # df_merged.columns = [tuple(col.split()) for col in df_merged.columns]\n",
    "    df_merged = df_merged.reindex(framedict['None_normal'].columns, axis=1)\n",
    "    df_merged_budget = df_merged_budget.reindex(framedict['None_normal'].columns, axis=1)\n",
    "\n",
    "    # print(df_merged)\n",
    "\n",
    "    # Fixed model order\n",
    "    history_order = [\"None_0\", \"No DH, no BI\", \n",
    "                    #  \"Only BI\", \n",
    "                        \"BART-D\", \"Full\", \"Pegasus-CD\", \"Pegasus-DS\", \"Pegasus-DS + BI\", \n",
    "                        \"Recent-1\", \"Recent-2\", \"Recent-4\", \"Recent-8\", \"Recent-10\", \"Recent-16\", \n",
    "                        \"Semantic-1\", \"Semantic-2\", \"Semantic-4\", \"Semantic-8\", \"Semantic-10\", \"Semantic-16\",\n",
    "                        ]\n",
    "    # remove history signals that are not in the data\n",
    "    history_order_chk = [h for h in history_order if h in df_merged.index]\n",
    "    df_merged = df_merged.reindex(history_order_chk)\n",
    "    history_order_chk = [h for h in history_order if h in df_merged_budget.index]\n",
    "    df_merged_budget = df_merged_budget.reindex(history_order_chk)\n",
    "\n",
    "\n",
    "    # Plot the merged df using the scatter_plot_pivoted_df function\n",
    "    f3 = f'plots/{dataset_prefix}/{metric}_merge_{target}.pdf'\n",
    "    scatter_plot_pivoted_df(df_merged[~df_merged.index.isin([\"None_0\", \"No DH, no BI\"])],metric, f3)\n",
    "\n",
    "    # Get the ROI\n",
    "    # df_delta = df_merged - df_merged.iloc[0]\n",
    "    # df_delta_budget = df_merged_budget - df_merged_budget.iloc[0]\n",
    "    # df_merged_ROI = 10_000 * df_delta / df_delta_budget\n",
    "    df_merged_ROI = calculate_ROI(df_merged, df_merged_budget)\n",
    "\n",
    "    # Plot the ROI\n",
    "    f4 = f'plots/{dataset_prefix}/{metric}_merge_{target}_ROI.pdf'\n",
    "    scatter_plot_pivoted_df(df_merged[~df_merged.index.isin([\"None_0\", \"No DH, no BI\"])],metric, f4, is_roi=True)\n",
    "\n",
    "    return df_merged, df_merged_budget, df_merged_ROI\n",
    "\n",
    "def merge_runs_pro(df_merged_normal, df_merged_ppl, metric):\n",
    "    # Copy the df_merged_normal and df_merged_ppl\n",
    "    df_merged_normal = df_merged_normal.copy()\n",
    "    df_merged_ppl = df_merged_ppl.copy()\n",
    "\n",
    "    # If columns are tuples, convert them to strings\n",
    "    if isinstance(df_merged_normal.columns[0], tuple):\n",
    "        df_merged_normal.columns = [\" \".join(col) for col in df_merged_normal.columns]\n",
    "        df_merged_ppl.columns = [\" \".join(col) for col in df_merged_ppl.columns]\n",
    "        \n",
    "    # Average runs by models+FS+normal/ppl)\n",
    "    zs_runs_n = [c for c in df_merged_normal.columns if \"ZS\" in c]\n",
    "    fs_runs_n = [c for c in df_merged_normal.columns if \"FS\" in c]\n",
    "    \n",
    "    # Create new df\n",
    "    df_merged = pd.DataFrame()\n",
    "    df_merged[('Model Avg.','ZS+Manual')] = df_merged_normal[zs_runs_n].mean(axis=1)\n",
    "    df_merged[('Model Avg.','FS+Manual')] = df_merged_normal[fs_runs_n].mean(axis=1)\n",
    "    df_merged[('Model Avg.','ZS+PPL')] = df_merged_ppl[zs_runs_n].mean(axis=1)\n",
    "    df_merged[('Model Avg.','FS+PPL')] = df_merged_ppl[fs_runs_n].mean(axis=1)\n",
    "\n",
    "    # Plot the merged df using the scatter_plot_pivoted_df function\n",
    "    f1 = f'plots/{dataset_prefix}/{metric}_merge.avg.pdf'\n",
    "    scatter_plot_pivoted_df(df_merged[~df_merged.index.isin([\"None_0\", \"No DH, no BI\"])],metric, f1)\n",
    "\n",
    "    return df_merged\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e050ca-f46e-4c38-afe8-dfb79d9ec474",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_type_groups = {\n",
    "    'normal': ['FS-ICL', 'ZS-ICL'],\n",
    "    'ppl': ['FS-ICL (ppl)', 'ZS-ICL (ppl)'],\n",
    "}\n",
    "metrics = ['BLEU', 'METEOR', 'rougeL', 'Bert-f1', 'BLEURT', 'DEB']\n",
    "\n",
    "# Start Processing\n",
    "filtered_df = df[df['History Signal'].notnull()]\n",
    "\n",
    "# Filter by metric\n",
    "for metric in metrics:\n",
    "    all_subframes = {}\n",
    "    if 'Persona Signal' in df:\n",
    "        # dataset_prefix = \"MSC\"\n",
    "        # Filter by persona\n",
    "        groups = filtered_df.groupby(['Persona Signal'])\n",
    "\n",
    "        # Find common baselines\n",
    "        # Persona = None, History = None, prompt_type=same\n",
    "        baseline_df = filtered_df[(filtered_df['Persona Signal'] == \"None\") & (filtered_df['History Signal'] == \"None\")]\n",
    "        for signal, sub_df in groups:\n",
    "            #if signal != \"None\":\n",
    "            #    _internal_baseline = sub_df[sub_df['History Signal'] == \"None\"]\n",
    "            #    if len(_internal_baseline) == 0:\n",
    "            #        sub_df_with_baseline = sub_df.append(baseline_df)\n",
    "            proc_sub_df_persona(sub_df, baseline_df, signal, prompt_type_groups, metric, all_subframes, dataset_prefix)\n",
    "            # if signal == \"None\":\n",
    "            #     raise \"Hell\"\n",
    "    else:\n",
    "        # dataset_prefix = \"TC\"\n",
    "        # Find common baselines\n",
    "        # Persona = None, History = None, prompt_type=same\n",
    "        baseline_df = filtered_df[(filtered_df['History Signal'] == \"None\")]\n",
    "\n",
    "        proc_sub_df_persona(filtered_df, baseline_df, \"NA\", prompt_type_groups, metric, all_subframes, dataset_prefix)\n",
    "\n",
    "    # raise Exception(\"Hell\")\n",
    "    # if dataset_prefix == \"MSC\":\n",
    "    if 'Persona Signal' in df:\n",
    "        df_merged_p, _, df_merged_p_ROI = merge_runs(all_subframes, metric, dataset_prefix, target=\"ppl\")\n",
    "        df_merged_n, _, df_merged_n_ROI = merge_runs(all_subframes, metric, dataset_prefix, target=\"normal\")\n",
    "        _ = merge_runs_pro(df_merged_n, df_merged_p, metric)\n",
    "    # Save all subframes to xlsx, one sheet per persona signal\n",
    "    # (signal, prompt_types) for all prompt type should be in same sheet for easy comparison\n",
    "\n",
    "    with pd.ExcelWriter(f'processed/{dataset_prefix}/{metric}.xlsx') as writer:\n",
    "        for key, value in all_subframes.items():\n",
    "            # remove multiindex \n",
    "            value.columns = [' '.join(col).strip() for col in value.columns.values]\n",
    "            value.to_excel(writer, sheet_name=key)\n",
    "\n",
    "        # if dataset_prefix == \"MSC\":\n",
    "        if \"Persona Signal\" in df:\n",
    "            # Save merged df\n",
    "            # fix column names\n",
    "            df_merged_p.columns = [' '.join(col).strip() for col in df_merged_p.columns.values]\n",
    "            df_merged_p.to_excel(writer, sheet_name=\"merged_ppl\")\n",
    "\n",
    "            # Save merged ROI\n",
    "            # fix column names\n",
    "            df_merged_p_ROI.columns = [' '.join(col).strip() for col in df_merged_p_ROI.columns.values]\n",
    "            df_merged_p_ROI.to_excel(writer, sheet_name=\"merged_ppl_ROI\")\n",
    "\n",
    "            # Save merged df\n",
    "            # fix column names\n",
    "            df_merged_n.columns = [' '.join(col).strip() for col in df_merged_n.columns.values]\n",
    "            df_merged_n.to_excel(writer, sheet_name=\"merged_normal\")\n",
    "\n",
    "            # Save merged ROI\n",
    "            # fix column names\n",
    "            df_merged_n_ROI.columns = [' '.join(col).strip() for col in df_merged_n_ROI.columns.values]\n",
    "            df_merged_n_ROI.to_excel(writer, sheet_name=\"merged_normal_ROI\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc52725",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_runs_pro(df_merged_n, df_merged_p, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subframes[\"Pegasus-CD_ppl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa25b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming all_subframes is a dictionary containing the subframes\n",
    "none_normal = all_subframes['None_normal'].loc[['None_1']]\n",
    "none_ppl = all_subframes['None_ppl'].loc[['None_1']]\n",
    "\n",
    "# display the subframes side by side\n",
    "pd.concat([none_normal, none_ppl], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9eb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[[\"History Signal\", \"Model\", \"Prompt Type\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9eb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d971af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "    #!/bin/bash\n",
    "    # if figlet is installed\n",
    "    if [ -x \"$(command -v figlet)\" ]; then\n",
    "        figlet \"Adios!\"\n",
    "    fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa83d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3b0ed3f3b8d2534ba0b286c748703f0af5e95709f70acd7080da9e41254233"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
